{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:24:42.584685Z",
     "start_time": "2024-05-10T21:24:42.582302Z"
    }
   },
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "from src.data_loading import load_equity_data, load_macro_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bf23afbb70af0158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:25:27.417128Z",
     "start_time": "2024-05-10T21:25:27.228677Z"
    }
   },
   "source": [
    "UNK: float = -99.99\n",
    "\n",
    "raw_data = load_equity_data(name=\"train\")\n",
    "R_t = raw_data[:, :, 0]\n",
    "X = raw_data[:, :, 1:]\n",
    "\n",
    "# Compute a mask to keep track of which values are available\n",
    "mask = R_t != UNK\n",
    "\n",
    "X_clean = X[mask]\n",
    "y_clean = R_t[mask]\n",
    "\n",
    "idxs = np.sum(mask, axis=1)\n",
    "idxs = np.cumsum(idxs)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6cb5047ae8745c36",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We start with a standard, cross-validated OLS regression to get some estimate of the baseline $R^2$ we can expect to achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a2139fc7d80ea",
   "metadata": {},
   "source": [
    "# Benchmark returns on features OLS"
   ]
  },
  {
   "cell_type": "code",
   "id": "6f77d3c319798f0a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-10T21:25:33.145133Z",
     "start_time": "2024-05-10T21:25:33.084358Z"
    }
   },
   "source": [
    "cross_cov = X_clean * y_clean[:, None]  # I_ti * R_t = F_tilde\n",
    "\n",
    "# Now mean over assets in period\n",
    "f_tilde = np.vsplit(cross_cov, idxs)\n",
    "f_tilde = [\n",
    "    np.mean(f, axis=0) for f in f_tilde if len(f) > 0\n",
    "]  # mean over assets in period\n",
    "f_tilde = np.row_stack(f_tilde)  # shape: (n_periods, n_factors)\n",
    "\n",
    "cov = np.cov(f_tilde.T)\n",
    "E_f_tilde = f_tilde.mean(axis=0)  # shape: (n_factors,), mean over periods\n",
    "\n",
    "# yields: theta_LS = (Sigma)^-1 * E[F_tilde]\n",
    "theta_LS = np.linalg.solve(cov, E_f_tilde)\n",
    "theta_LS"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c2ba0e14b61a3ba6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-10T21:25:34.291896Z",
     "start_time": "2024-05-10T21:25:34.065567Z"
    }
   },
   "source": [
    "# Now backtest it\n",
    "w = X_clean @ theta_LS\n",
    "\n",
    "monthly_portfolio_return = zip(\n",
    "    np.split(y_clean, idxs, axis=0), np.split(w, idxs, axis=0)\n",
    ")\n",
    "monthly_portfolio_return = np.array(\n",
    "    [\n",
    "        np.sum(r * w) / np.sum(np.abs(w))\n",
    "        for r, w in monthly_portfolio_return\n",
    "        if len(r) > 0\n",
    "    ]\n",
    ")\n",
    "\n",
    "equity = np.cumsum(monthly_portfolio_return)\n",
    "\n",
    "plt.plot(equity)\n",
    "plt.show()"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1cd9103a16c8db44",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-10T21:25:35.261494Z",
     "start_time": "2024-05-10T21:25:35.166015Z"
    }
   },
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def compute_portfolio_return_for_linear_portfolio_weights(\n",
    "    theta: np.ndarray, raw_data: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    R_t = raw_data[:, :, 0]\n",
    "    X = raw_data[:, :, 1:]\n",
    "\n",
    "    mask = R_t != UNK\n",
    "    X_clean = X[mask]\n",
    "    y_clean = R_t[mask]\n",
    "\n",
    "    idxs = np.sum(R_t != UNK, axis=1)\n",
    "    idxs = np.cumsum(idxs)\n",
    "\n",
    "    w = X_clean @ theta\n",
    "\n",
    "    monthly_portfolio_return = zip(\n",
    "        np.split(y_clean, idxs, axis=0), np.split(w, idxs, axis=0)\n",
    "    )\n",
    "    monthly_portfolio_return = np.array(\n",
    "        [\n",
    "            np.sum(r * w) / np.sum(np.abs(w))\n",
    "            for r, w in monthly_portfolio_return\n",
    "            if len(r) > 0\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return monthly_portfolio_return\n",
    "\n",
    "\n",
    "dat = load_equity_data(name=\"valid\")\n",
    "equity_curve = compute_portfolio_return_for_linear_portfolio_weights(\n",
    "    theta_LS, dat\n",
    ")\n",
    "equity_curve"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "44442e09b8d66033",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-10T21:25:37.046724Z",
     "start_time": "2024-05-10T21:25:36.011908Z"
    }
   },
   "source": [
    "eq_curves = []\n",
    "stats = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for ds in (\"train\", \"valid\", \"test\"):\n",
    "    dat = load_equity_data(name=ds)\n",
    "    e = compute_portfolio_return_for_linear_portfolio_weights(theta_LS, dat)\n",
    "    stats[ds][\"mean\"] = np.mean(e)\n",
    "    stats[ds][\"std\"] = np.std(e)\n",
    "    stats[ds][\"sharpe\"] = stats[ds][\"mean\"] / stats[ds][\"std\"]\n",
    "    stats[ds][\"VaR\"] = np.percentile(e, 5)\n",
    "\n",
    "    e = np.cumprod(1 + e)\n",
    "    stats[ds][\"total_return\"] = e[-1]\n",
    "    stats[ds][\"max_drawdown\"] = np.max(np.maximum.accumulate(e) - e)\n",
    "    eq_curves.append(e)\n",
    "\n",
    "eq_curves = np.concatenate(eq_curves)\n",
    "# eq_curves = np.exp(eq_curves) * 100.0\n",
    "# log scale on the y axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(eq_curves)\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame(stats)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c56b408a9f7a9653",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Betas and Fama Macbeth Regression for the one-factor model\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "85130ab8dbe736d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:25:38.143963Z",
     "start_time": "2024-05-10T21:25:37.426234Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "F_t = compute_portfolio_return_for_linear_portfolio_weights(theta_LS, raw_data)\n",
    "\n",
    "# Replace UNK with nan and take the nanmean then\n",
    "R_t_nan = R_t.copy()\n",
    "R_t_nan[R_t_nan == UNK] = np.nan\n",
    "\n",
    "\n",
    "def compute_beta(\n",
    "    r_t: np.ndarray, f_t: np.ndarray, estimate_alpha: bool = False\n",
    ") -> float:\n",
    "    \"\"\"Returns a tuple, beta for a single asset.\"\"\"\n",
    "    reg = LinearRegression(fit_intercept=estimate_alpha)\n",
    "\n",
    "    # Find the indexes that are not nan for the r_t\n",
    "    clean_indexes = np.isfinite(r_t)\n",
    "    reg.fit(f_t[clean_indexes, None], r_t[clean_indexes])\n",
    "\n",
    "    beta: float = reg.coef_[0]\n",
    "\n",
    "    return beta\n",
    "\n",
    "\n",
    "beta = [compute_beta(r, F_t) for r in R_t_nan.T]\n",
    "beta = np.array(beta)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "57340bc28ede5a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:25:38.376279Z",
     "start_time": "2024-05-10T21:25:38.145473Z"
    }
   },
   "source": [
    "# Have to be careful with nans in the asset returns\n",
    "# Note: there is quite the difference whether we regress an intercept (alpha) or not to find the beta\n",
    "# See above function to find the beta\n",
    "# beta = np.nanmean(R_t_nan * F_t[:, None], axis=0)\n",
    "stock_indexes = np.arange(len(beta))\n",
    "sorted_indexes = np.argsort(beta)\n",
    "sorted_R_t = R_t_nan[:, sorted_indexes]\n",
    "\n",
    "decile_portfolios = [\n",
    "    np.nanmean(s, axis=1)\n",
    "    for s in np.array_split(sorted_R_t, 10, axis=1)\n",
    "    if len(s) > 0\n",
    "]\n",
    "port_betas = [\n",
    "    np.mean(b) for b in np.array_split(beta[sorted_indexes], 10) if len(b) > 0\n",
    "]\n",
    "port_betas = np.array(port_betas)\n",
    "\n",
    "# And plot the cumulative returns of the decile portfolios\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Put them all in one plot\n",
    "for i, r in enumerate(decile_portfolios):\n",
    "    # Replace nan return with 0.0\n",
    "    cleaned_r = np.nan_to_num(r)\n",
    "    cleaned_r = cleaned_r / np.std(cleaned_r)\n",
    "    equity = np.cumsum(cleaned_r)\n",
    "\n",
    "    axs[0].scatter(np.arange(len(equity)), equity, label=f\"Decile {i + 1}\")\n",
    "\n",
    "    # label the decile\n",
    "    axs[0].text(0, equity[-1], f\"Decile {i + 1}\")\n",
    "\n",
    "\n",
    "# And make a scatter plot with expected portfolio return and portfolio beta for the decile portfolios\n",
    "exp_portf_return = [np.nanmean(r) for r in decile_portfolios if len(r) > 0]\n",
    "axs[1].scatter(port_betas, exp_portf_return)\n",
    "\n",
    "# And of course add a regression line that shows the slope (market price of risk)\n",
    "reg = LinearRegression(fit_intercept=True).fit(\n",
    "    X=port_betas[:, None], y=exp_portf_return\n",
    ")\n",
    "\n",
    "# And draw that slope as a line in the right chart\n",
    "p: float = 0.1\n",
    "x = np.linspace(np.min(port_betas) * (1 + p), np.max(port_betas) * (1 + p), 100)\n",
    "y = reg.predict(x[:, None])\n",
    "\n",
    "axs[1].plot(\n",
    "    x, y, label=f\"Market price of risk: {reg.coef_[0]:.2f}\", color=\"red\"\n",
    ")\n",
    "\n",
    "# Set y axis scale to [-0.1, 0.1]\n",
    "axs[1].set_ylim([-0.1, 0.1])\n",
    "\n",
    "# Add legend\n",
    "plt.show()"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "119249fd0eae9ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:25:42.222501Z",
     "start_time": "2024-05-10T21:25:42.100410Z"
    }
   },
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "expected_returns = np.nanmean(R_t_nan, axis=0)\n",
    "sm.OLS(endog=expected_returns, exog=sm.add_constant(beta)).fit().summary()"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6fcb68e5cd1bb179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:29:42.371649Z",
     "start_time": "2024-05-10T21:29:42.356989Z"
    }
   },
   "source": [
    "# And make a regression plot with seaborn\n",
    "reg_df = pd.DataFrame(dict(portfolio_return=expected_returns, beta=beta))\n",
    "\n",
    "# Make it a bit more transparent\n",
    "sns.regplot(\n",
    "    data=reg_df, x=\"beta\", y=\"portfolio_return\", scatter_kws={\"alpha\": 0.2}\n",
    ")\n",
    "plt.show()"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "95a1c527c4aaf643",
   "metadata": {},
   "source": [
    "# Time-Varying betas with another linear regression\n",
    "\n",
    "$$\\beta_{t, i} = \\gamma ^T I_{t, i}$$\n",
    "\n",
    "$\\gamma$ is constant OLS regression coefficient obtained from *regression of $R_{t,i} F_t$ on $I_{t,i}$*."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:29:45.244616Z",
     "start_time": "2024-05-10T21:29:45.017568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "F_t = []\n",
    "\n",
    "w = X_clean @ theta_LS\n",
    "w_splitted = np.split(w, idxs, axis=0)\n",
    "returns_splitted = np.split(y_clean, idxs, axis=0)\n",
    "\n",
    "for w, r in zip(w_splitted, returns_splitted):\n",
    "    if len(w) == 0:\n",
    "        continue\n",
    "\n",
    "    # Compute the factor return\n",
    "    f = np.sum(r * w) / np.sum(np.abs(w))\n",
    "    # f = np.sum(r * w) / np.sqrt(w.dot(w))\n",
    "    F_t.append(f)\n",
    "\n",
    "F_t = np.array(F_t)\n",
    "F_t = F_t / np.std(F_t)\n",
    "\n",
    "plt.plot(np.cumsum(F_t))"
   ],
   "id": "2c648914b3e94fe8",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "db6ec3e82e3fba2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:29:46.894390Z",
     "start_time": "2024-05-10T21:29:45.954787Z"
    }
   },
   "source": [
    "# Regression to yield an estimate for the time-varying beta\n",
    "regression_target = (R_t_nan * (F_t[:, None]))[mask]\n",
    "reg = LinearRegression(fit_intercept=False).fit(X=X_clean, y=regression_target)\n",
    "\n",
    "beta_ls = reg.predict(X_clean)\n",
    "beta_splitted = np.split(beta_ls, idxs, axis=0)\n",
    "\n",
    "n_quantiles: int = 10\n",
    "decile_portfolios = [list() for _ in range(n_quantiles)]\n",
    "\n",
    "\n",
    "for i, (b, r) in enumerate(zip(beta_splitted, returns_splitted)):\n",
    "    if len(b) == 0:\n",
    "        continue\n",
    "\n",
    "    # Sort the betas\n",
    "    sorted_indexes = np.argsort(b)\n",
    "    sorted_R_t = r[sorted_indexes]\n",
    "    sorted_R_t = sorted_R_t[~np.isnan(sorted_R_t)]\n",
    "\n",
    "    # Drop the nans and split them into decile portfolios\n",
    "    portf_returns = np.array_split(sorted_R_t, n_quantiles)\n",
    "    portf_returns = [np.nanmean(r) for r in portf_returns if len(r) > 0]\n",
    "\n",
    "    for j, r in enumerate(portf_returns):\n",
    "        decile_portfolios[j].append(float(r))\n",
    "\n",
    "\n",
    "decile_portfolios = np.row_stack(decile_portfolios)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9e63ec3dae648e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:29:47.881798Z",
     "start_time": "2024-05-10T21:29:47.713196Z"
    }
   },
   "source": [
    "# And plot the equity curves like before\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "for i, r in enumerate(decile_portfolios):\n",
    "    equity = np.cumsum(r) / np.std(r)\n",
    "    ax.scatter(np.arange(len(equity)), equity, label=f\"Decile {i + 1}\")\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:29:48.475674Z",
     "start_time": "2024-05-10T21:29:48.472499Z"
    }
   },
   "cell_type": "code",
   "source": "np.mean(F_t) / np.std(F_t)",
   "id": "93cf84d438da35bd",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:29:49.185714Z",
     "start_time": "2024-05-10T21:29:49.155622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# And now calculate R_hat from that\n",
    "# beta * F_t / (b^T b)\n",
    "\n",
    "eps = []\n",
    "\n",
    "for i, (b, r, f) in enumerate(zip(beta_splitted, returns_splitted, F_t)):\n",
    "    if len(b) == 0:\n",
    "        continue\n",
    "\n",
    "    # Compute the residuals\n",
    "    # r_hat = b * f / np.sum(b**2)\n",
    "    r_hat = b.dot(r) * b / (np.sum(np.square(b)))\n",
    "    # r_hat = b.dot(r) * b / np.sqrt(np.sum(b**2))\n",
    "    # r_hat = b.dot(r) * b / np.sum(np.absolute(b))\n",
    "    e = r - r_hat\n",
    "    eps.extend(e)\n",
    "\n",
    "\n",
    "eps = np.array(eps)"
   ],
   "id": "f7a9147fac49dab",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:29:50.083999Z",
     "start_time": "2024-05-10T21:29:50.076781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# r2 = 1 - (np.sum(eps**2) / np.sum(y_clean**2))\n",
    "r2 = 1 - (\n",
    "    np.sum([np.mean(e**2) for e in np.split(eps, idxs, axis=0) if len(e) > 0])\n",
    "    / np.sum(\n",
    "        [np.mean(r**2) for r in np.split(y_clean, idxs, axis=0) if len(r) > 0]\n",
    "    )\n",
    ")\n",
    "\n",
    "r2"
   ],
   "id": "f916b8706bf6e8e8",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T10:18:06.883587Z",
     "start_time": "2024-04-24T10:18:06.881591Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ad66fd5a5e748d60",
   "execution_count": 16,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
